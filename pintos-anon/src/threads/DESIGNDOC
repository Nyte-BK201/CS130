			+--------------------+
			| CS 140             |
			| PROJECT 1: THREADS |
			| DESIGN DOCUMENT    |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.
Zhongyue Lin    <linzhy@shanghaitech.edu.cn>
Mengying Wu <wumy1@shanghaitech.edu.cn>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h:
/* Record the alarm pos and wake-up time */
    int64_t wake_up_time;// the absolute time the thread should wake up
    struct list_elem alarm_elem;
timer.c:
    /* alarm thread sleeping list */
    static struct list alarm_list;

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

We init an alarm list at beginning where contains sleeping threads  
and be ordered by threads' wake up time. When call timer_sleep(),
first check if it is a fair time. Next, disable interrupt and record the
previous interrupt status. Then take out the current thread, change 
its wake_up_time to the absolute time it should wake up, and insert it
to the alarm_list according to its wake_up_time. After that, block it and
set the interrupt level to the previous status.
The timer interrupt handler mainly check if there is any thread should
wake up. While the alarm_list is not empty, everytime check if the first 
item's wake_up_time is less than current time, if yes then unblock it and
remove it from alarm_list.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

We make an alarm_list to record the sleeping threads and sort them by 
wake_up_time.
Everytime we only need check the first element in the alarm_list, if its 
wake_up_time is
larger than current time, this means no thread in the list need to wake 
up, otherwise we unblock it the check the next one. By this way we can 
ensure the time waste on those who remain sleeping is up to one thread, 
acutually just one compare function.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

By disabling interrupt before any thread wants to sleep, the race conditions
are avoided. When multiple threads call timer_sleep(), only one thread can 
operate the alarm_list and others will be obstructed, we need to protect 
thread_current() is always one thread. After the thread blocks itself, change 
back the original interrupt level, then other threads can sleep themselves one
by one.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

By disabling interrupt before any thread wants to sleep, the race conditions
are avoided. If the timer interrupt occurs before we disable interrupt or 
after we change back the original interrupt, then nothing wrong would 
happen, only timer_interrupt() would operate alarm_list this time, it would 
check if there is any thread need to wake up, and the thread who called 
timer_sleep() hasn't do anything to itself or has already blocked itself.
If the timer interrupt occurs after we disable interrupt, it would find itself 
unable to interrupt the timer_sleep(), this time only the thread who called 
timer_sleep() can operate the alarm_list and block itself.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The design is superior to other design by two reasons.
1. We record an absolute waking-up time point when a thread want to sleep,
then when we check if a thread should wake up, we only need to compare
its wake_up_time with current time instead of maintaining a decreasing 
time bucket every tick. 
2. We create a priority queue alarm_list to preserve sleeping threads. We sort
it by their waking-up time, which ensuring that the first thread is always the 
earliest thread need to wake up. If the first thread doesn't need to wake up,
then threads after it also don't need to wake up. We only need one compare
function to check if there are any other threads want to wake up instead of 
check every sleeping thread every tick.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h: 
	int priority;                        /* Current Priority. */
	/* Pair Lock to this priority; NULL if it is default */
    struct lock *priority_lock_master;   
    /* Priority donated by other threads;
      we also save the donation's belonging lock */
    int stored_priority[30];
    struct lock *stored_lock_master[30];
    int stored_index;

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Whenever H thread donate to L, we set L's priority to H and save previous to
stored_priority[] and save this donation's lock in pairs. 
Thus, every priority is bound with a lock(initial priority's lock is NULL).

Once a lock is released, we delete all the priorities got from this lock, 
and find the right front one in the remaining. Since the right most priority
pair is ensured to be highest, the algorithm is quite efficient.

Nested case:
|---| wait L1 		|---|	wait L2     |---|
|-H-|   -->			|-M-|    -->        |-L-|
|---|  				|-1-|				|-2-|

Here, L holds Lock2 and M holds Lock1, M donate L a priority and blocked;
L recive it and pair this priority with L2 (M,L2);
Now, H wants L1, H donate M, M pair it with L1 (H,L1), M get unblocked,
Then M checked if L2 is released, if not, donate current priority to holder,
L then recive and pair (H,L2). 
H,M is blocked, and H,M,L's priorities are all High.

L release L2, unblock M, and give up pair (H,L2),(M,L2), switch to stored 
(L,NULL). Now M is (H,L1) higher than L (M,L2), L yields immediately and M runs.
M release L1, wake up H, give up (H,L1), switech to (M,NULL), yields.
In this way, we solve this problem neatly.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We use list_insert_ordered to ensure a priority queue to sema/lock/cond
waiter list. Every thread's priority is sure to be the highest in any
condition, so that waking up the front of the list meets the requirement.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Check if lock has a holder. If not, gets the lock. Otherwise, loop:
	If current priority is higher than lock holder, donate it,
	Add to lock wait list, Block
Once nested donation happens, the loop keeps thread donating to lock
holder to make sure holder always get the proper priority to run in priority
scheduling.
So the nested donation is handled by recursive donation to lower thread.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

Remove all the priorities got from this lock, Switch to the highest in
remaining(which is right most one in stored_priority[]).Sema up(which 
wakes up the highest priority waiter).

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

L is running thread_set_priority, and setting a new priority; before
finshing it, H kicks in and donate H to L for whatever locks and H blocked;
L is now High Priority but it continues priority set which results in 
H's donation is lost.

My implementation's thread priority is always the highest. It could be
original or donated. when setting new priority:
1. If current priority gets from donation, original is stored in index 0
	we change the priority stored in stored_priority[0]
2. If current is original, we change it

A lock does not help because lock itself requires threads have proper priority,
and the problem could also happens to this function's temporary lock.

I avoid it by disabling interrupt inside this function.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The implementation is very neat and clear that we don't need to change
the property 'priority' which saves a lot works to coordinate the original
code. The assumption made that priority is always the highest is useful
in scheduling. And the pair (Priority,Lock) is quite elegant that we do
not care about 'which thread is waiting for which lock I am holding'.

Other design like implementing a link list when donation happens requires
a lot editing on original codes and wastes space. The superior is the 
abstraction that we pair the donation and its lock to make sure a thread
with a lock waiting by others could always get a enough priority to release
it and maintain it an array to make sure multiple donation is working.
Array is quite simple to manipulate, right?

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h: 
	/* nice and recent_cpu */
    int nice;
    fixed_point recent_cpu;
thread.c: 
	/* load average to advance scheduler */
	static fixed_point load_avg;
fixed-point.h /* Float Point with integer implementation */

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0		0   0   0   63  61  59		A
 4		4	0	0	62	61  59		A
 8		8	0	0	61	61	59		B
12		8	4	0	61  60  59		A
16		12  4   0   60  60  59      B
20		12	8	0	60  59  59      A
24		16  8   0   59  59  59      C
28		16  8   4   59  59  58      B
32		16  12  4   59  58  58      A
36		20  12  4   58  58  58      C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

Yes. Timer ticks 8,16,24,36 we have multiple highest priority threads
in the ready list. The scheduler does not have any specification in 
choosing multiple highest priority threads, so I first try "First Come 
First Serve". A thread is to run if it comes with that priority first
in the ready list.

But in practice, after updating all recent_cpu and priorities then sort
will reduce the time consumption in timer_interrupt handler and have a
better performance. So we are having a choice between performance and 
predictable behavior in the situation where I do not use 64 queues. I
choose a better performance by using list_sort since there is not a 
particular requirement to ordering.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

A complex scheduling interrupt context will consume more time which 
can not be  interrupted. This will reduce the concurrency and 
performance so that I put code inside as less as I could, and keep it 
functioning in the meantime.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

The design consumes no extra space comparing to no advanced scheduler.
And the code is simple to keep balance its functioning and performance
inside a interrupt context.

However, there are disadvantages in updating priorities. The ordering
between multiple highest priority threads is designed by list_sort
(quick sort) which is uncertain to some extent.

I would considering using 64 queues so that I can keep both performance
and ordering since it will not cause too much overhead in memory consumption.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?