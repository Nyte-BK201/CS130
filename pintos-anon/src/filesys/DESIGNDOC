        	 +-------------------------+
		     | CS 140                  |
		     | PROJECT 4: FILE SYSTEMS |
		     | DESIGN DOCUMENT         |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Zhongyue Lin <linzhy@shanghaitech.edu.cn>
Mengying Wu <wumy1@shanghaitech.edu.cn>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

filesys/inode.c:
/* On-disk inode.
   Must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct inode_disk
  {
    block_sector_t sectors[125];        /* Lv0 0~122, lv1 123, lv2 124 */
    uint32_t isdir;                     /* 0 file, 1 dir */
    off_t length;                       /* File size in bytes. */
    unsigned magic;                     /* Magic number. */
  };

/* In-memory inode. */
struct inode 
  {
    struct list_elem elem;              /* Element in inode list. */
    block_sector_t sector;              /* Sector number of disk location. */
    int open_cnt;                       /* Number of openers. */
    bool removed;                       /* True if deleted, false otherwise. */
    struct lock lock;                   /* lock to manipulate this inode */

    int deny_write_cnt;                 /* 0: writes ok, >0: deny writes. */
    off_t true_length;                  /* sync with read/write race condition*/
    struct inode_disk data;             /* Inode content. */
  };

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

inode itself contains 123 LV0 sectors, 123*512 bytes
LV1 contains 128 LV0 sectors, 128*512 bytes
LV2 contains 128 LV1 sectors, 128*128*512 bytes
Total 8,517,120 bytes, which is roughtly 8.12MB

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

When a process tries to extend a file, it will first execute 
lock_acquire(&inode->lock). So multi-processes will compete to acquire the lock
and only one process can extend it at one time.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

Our implementation limits the reading that only after the whole writing to a 
file finishs, reading process will be allowed to get the data. Otherwise, 
return zero bytes read.
In details, inode->true_length records the length of none-zero data(which has
been written by B). It is updated after whole writing finishs. inode_read_at()
will check true_length at the very beginning to see if there is none-zero data
to read. And no lock is required to inode_read_at().

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

Readers will not require any synchronizations since our design let 
writers to coordinate. Extending a file requires inode->lock, and writers to 
the same file exclusively extend it. Besides extension, no synchronization is 
required, so the concurrency and fairness are both guaranteed.
Also the implementation is stable to the condition of competing writing/reading
that only finished data can be fetched.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

Yes. A doubly indirect block will meet the requirement of 8MB file size. So, 
we focus on small files which are most parts of a disk. Total 123 direct blocks
counts up to 62,976 bytes is a good number to contain small files which will
reduce the IO time to disk. Also one indirect blocks contains 65,536 bytes, 
which sum up to 128,512 bytes, roughtly 0.12MB for a middle sized file.

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

threads/thread.h: 
struct thread{
	...
	struct dir *cwd;                    /* current directory */
	...
};

/* fd entry */
struct fd_entry{
  struct file *file;  /* file entry */
  struct dir *dir;    /* dir entry  */
};

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

Our parsing routine states as:
1. Remove front space and check the very first character, if it is "/", open 
	root dir, otherwise, open thread_current()->cwd as base dir.
2. Filtering "/" character by strtok_r(). Lookup the token in base dir, if
	current token is found, replace previous base dir by new one.
3. Loop until we are holding the last token. We do not need to search for last
	token and we just save it and return.
One special reminder is that, due to the feature of strtok_r(), the parser can 
not handle "/" so it has to be handled outside the parser as a special case.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

Add & remove a directory will require the process to hold the inode->lock.
We limits every lookup/add/remove directory action by inode_lock()/ 
inode_unlock() to maintain only one process can manipulates a base dir such as
adding a new file/dir to base dir, removing a file/dir in the base dir or even 
lookup a file/dir in the base dir. 
Every action which affects other process will have to obtain the base dir's 
inode->lock. 

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

No. Our implementation checks the directory to be removed to ensure there is no
file or dir inside except "." and "..". Any remove syscall to a none-empty dir 
will fail.
Also, the directory's inode is checked whether there is any other opening by 
seeing the inode->open_cnt. If it is in use as a process's cwd or opened by 
other process, its open_cnt must be larger than 1 since cwd is a opening dir.

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

In pintos, every process only has one thread, so keeping cwd in struct thread 
is keeping it in process. The design here maintains both uniqueness and 
inheritance of cwd. We can easily inherit a cwd when executing a child process
and use a process itself's cwd without any searching.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In filesys/cache.h:

struct cache_entry
{
    block_sector_t sector;             /* sector number of disk location */
    uint8_t data[BLOCK_SECTOR_SIZE];   /* data of the sector */
    bool dirty;                        /* whether it has been modified */
    bool accessed;                     /* whether it has been accesses recently */
    struct lock cache_lock;            /* lock for each cache_entry */
};

/* Use a list to store sectors which are requested to read ahead */
struct read_ahead_entry {
    block_sector_t sector;             /* the requested sector id */
    struct list_elem elem;
};

In filesys/cache.c:

/* Buffer cache with 64 entries. */
struct cache_entry* buffer_cache[BUFFER_CACHE_SIZE];

/* A lock for the whole buffer cache. */
struct lock buffer_cache_lock;

/* Store read_ahead requests with sector id. */
struct list read_ahead_list;

/* A lock for read_ahead_list. */
struct lock read_ahead_lock;

/* Condition for read_ahead. */
struct condition read_ahead_cond;

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

We use clock algorithm as my cache replacement algorithm. Circularly
check the cache_entries in buffer cache, if it has been recently accessed,
set `accesses' as false, else evict it and break the loop. When evicting, 
if it has been modified, write back the sector from `data' to disk.
During the implementation, lock the cache_entry's lock before check its
status and unlock it before go to the next entry.
The clock algorithm is used after the buffer cache is full, before that
just traverse the buffer cache and find a spare id to return.

>> C3: Describe your implementation of write-behind.

When a thread wants to write a sector, it calls cache_write(). Firstly,
search the sector in buffer cache, if it is not in cache then get an free
index by cache_evict() and read it into cache, finally get its index in
buffer cache. Then write the given buffer into cache.
For write-behind, run a background thread cache_clear_periodic_background(),
check the whole buffer cache every second, write all modified sectors 
from cache into disk and mark the cache_entry as not modified.

>> C4: Describe your implementation of read-ahead.

When a thread wants to read ahead a sector, it calls cache_read_ahead().
It commits a request to read ahead the sector, pushs the sector into 
read_ahead_list, then signals cache_read_ahead_background() to wake up
from wait.
Run a background thread cache_read_ahead_background(), wait condition
`read_ahead_cond' until read_ahead_list isn't empty, then take out the
sectors in the list and read them into cache all at once. 

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

I use a lock `buffer_cache_lock' for whole buffer cache. cache_evict()
is called inside cache_write() and cache_read() after `buffer_cache_lock'
is locked. When one process is actively reading or writing data in 
buffer cache, it will hold the lock and other processes cannot even go 
into cache_evict(). If some process is in cache_evict(), then it must 
be holding the buffer_cache_lock, which means other processes cannot 
read or write.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

Besides a lock for whole buffer cache, each block_entry has a lock 
`cache_lock'. cache_read(), cache_write() and cache_clear() all lock
`buffer_cache_lock' when they are called and unlock before finish,
so they are mutual exclusion. Since cache_evict() is called after 
`buffer_cache_lock' is locked in cache_read() and cache_write(), 
other processes cannot access the block by these three functions.

Considering cache_search() only refers to the sector index of the 
cache_entry, it doesn't matters when evicting.

In cache_evict(), lock each cache_entry's `cache_lock' before checking
and modifying its status, and unlock after it. This prevents other
process access when evicting.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

A file workload likely to benefit from buffer caching is reading or 
writing the same sector repeatedly in disk. Workloads likely to benefit
from read-ahead is reading a file sequentially, it may promise half
content to be in cache ahead of time and operates more efficiently. 
Workloads likely to benefit from write-behind is writing the same sector
frequently to disk, by write-behind it only need write once to block
which save a lot of time and not hinder synchronization.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?